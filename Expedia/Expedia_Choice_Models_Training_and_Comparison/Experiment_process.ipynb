{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from True_Model import true_model\n",
    "from copy import deepcopy\n",
    "import training_function as tp\n",
    "import build_new_data as bnd\n",
    "import assortment as at\n",
    "import warnings\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from  new_transformer_combination import Modifiled_Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the new traing data or testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 13)\n",
      "(2, 10000, 30, 12)\n",
      "(2, 10000, 30, 22)\n"
     ]
    }
   ],
   "source": [
    "choice_size = 30\n",
    "order_num = 10000\n",
    "file_name = \"test\"\n",
    "\n",
    "next_train_data = bnd.generate_data(order_num,int(choice_size))\n",
    "print(next_train_data.shape)\n",
    "next_train_data.to_csv(file_name+\"_dataset\\\\\"+str(order_num)+'.csv',index=False)\n",
    "\n",
    "pro = true_model.predict(next_train_data).detach().numpy()\n",
    "pro = pro[:,0:choice_size]\n",
    "#pro[:,-1] = 1 - np.sum(pro[:,0:choice_size],axis = 1)\n",
    "label = np.zeros(shape = pro.shape)\n",
    "for i in range(pro.shape[0]):\n",
    "    if np.random.binomial(1, np.sum(pro[i]), 1) > 0:\n",
    "        index = np.argmax(np.random.multinomial(1, pro[i]/np.sum(pro[i]), 1))\n",
    "        label[i,index] = 1\n",
    "label = label[:,0:choice_size]\n",
    "pro = pro[:,0:choice_size]\n",
    "\n",
    "\n",
    "\n",
    "del_feature = ['srch_id','booking_bool']\n",
    "features = [i for i in next_train_data.columns if i not in del_feature]\n",
    "data_np = np.array(next_train_data[features])\n",
    "data_np_cate = np.zeros(shape = data_np.shape)\n",
    "for idx,item in enumerate([6, 10, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2]):\n",
    "    if item !=1 :\n",
    "        data_np_cate[:,idx] = data_np[:,idx]\n",
    "        data_np[:,idx] = 1\n",
    "scaler = MinMaxScaler().fit(data_np)\n",
    "data_np = scaler.transform(data_np)\n",
    "for idx,item in enumerate([6, 10, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2]):\n",
    "    if item !=1 :\n",
    "        data_np[:,idx] = 1\n",
    "\n",
    "data_np = data_np.reshape(order_num,int(choice_size),-1)\n",
    "data_np_cate = data_np_cate.reshape(order_num,int(choice_size),-1)\n",
    "total_train_data = np.array([data_np_cate,data_np])\n",
    "\n",
    "\n",
    "np.save(file_name+\"_dataset\\\\data_\"+'_'+str(order_num)+'.npy',total_train_data)\n",
    "np.save(file_name+\"_dataset\\\\label_\"+'_'+str(order_num)+'.npy',label)\n",
    "np.save(file_name+\"_dataset\\\\pro_\"+'_'+str(order_num)+'.npy',pro)\n",
    "print(total_train_data.shape)\n",
    "\n",
    "data_temp = np.zeros((order_num, choice_size, 6))\n",
    "data_cate_temp = np.zeros((order_num, choice_size, 4))\n",
    "for i in range(order_num):\n",
    "    min1 = np.min(total_train_data[1,i,:,5])\n",
    "    max1 = np.max(total_train_data[1,i,:,5])\n",
    "    mean1 = np.mean(total_train_data[1,i,:,5])\n",
    "    min2 = np.min(total_train_data[1,i,:,6])\n",
    "    max2 = np.max(total_train_data[1,i,:,6])\n",
    "    mean2 = np.mean(total_train_data[1,i,:,6])\n",
    "    data_temp[i,:,0] = min1\n",
    "    data_temp[i,:,1] = max1\n",
    "    data_temp[i,:,2] = mean1\n",
    "    data_temp[i,:,3] = min2\n",
    "    data_temp[i,:,4] = max2\n",
    "    data_temp[i,:,5] = mean2\n",
    "    for j in range(choice_size):\n",
    "        if total_train_data[1,i,j,5] == np.min(total_train_data[1,i,:,5]):\n",
    "            data_cate_temp[i,j,0] = 1\n",
    "        if total_train_data[1,i,j,5] == np.max(total_train_data[1,i,:,5]):\n",
    "            data_cate_temp[i,j,1] = 1\n",
    "        if total_train_data[1,i,j,6] == np.min(total_train_data[1,i,:,6]):\n",
    "            data_cate_temp[i,j,2] = 1\n",
    "        if total_train_data[1,i,j,6] == np.max(total_train_data[1,i,:,6]):\n",
    "            data_cate_temp[i,j,3] = 1\n",
    "data_with_assort_info = np.array([np.concatenate([total_train_data[0],np.zeros((order_num, choice_size, 6)),data_cate_temp],axis = 2),np.concatenate([total_train_data[1],data_temp,np.ones((order_num,choice_size,4))],axis = 2)])\n",
    "print(data_with_assort_info.shape)\n",
    "np.save(file_name+'_dataset\\\\data_with_assort_info_'+str(order_num )+'.npy',data_with_assort_info)\n",
    "\n",
    "next_train_data[\"booking_bool\"] = label.flatten()\n",
    "next_train_data.to_csv(file_name + \"_dataset_for_transformer\\\\{}.csv\".format(order_num),index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the decision-test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1000, 100, 12)\n"
     ]
    }
   ],
   "source": [
    "next_valid_data = bnd.generate_data(1000,100)\n",
    "del_feature = ['srch_id','booking_bool']\n",
    "features = [i for i in next_valid_data.columns if i not in del_feature]\n",
    "\n",
    "data_np = np.array(next_valid_data[features])\n",
    "data_np_cate = np.zeros(shape = data_np.shape)\n",
    "for idx,item in enumerate([6, 10, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2]):\n",
    "    if item !=1 :\n",
    "        data_np_cate[:,idx] = data_np[:,idx]\n",
    "        data_np[:,idx] = 1\n",
    "data_np = scaler.transform(data_np)\n",
    "for idx,item in enumerate([6, 10, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2]):\n",
    "    if item !=1 :\n",
    "        data_np[:,idx] = 1\n",
    "\n",
    "data_np = data_np.reshape(1000,100,-1)\n",
    "data_np_cate = data_np_cate.reshape(1000,100,-1)\n",
    "valid_data = np.array([data_np_cate,data_np])\n",
    "print(valid_data.shape )\n",
    "next_valid_data.to_csv('new_products\\\\next_valid_data'+'.csv',index=False)\n",
    "np.save('new_products\\\\valid_data_'+'.npy',valid_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 MNL-Based Choice Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Training the MNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"trained_models\\\\MNL_parameters_\"+str(order_num)+\".pt\"\n",
    "model_MNL = tp.train_data(data,label,NUM_EPOCHS = 100,BATCH_SIZE = 32,LR = 0.01,path = PATH,feature_column=feature_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MNL Top1-acc: 0.2091\n",
      " MNL Top3-acc: 0.4363\n",
      " Averaged raito of MNL: 5.939736748902371\n",
      "RMSE of MNL: 0.0217\n"
     ]
    }
   ],
   "source": [
    "PATH = \"trained_models//MNL_parameters_\"+str(order_num)+\".pt\"\n",
    "model_MNL = torch.load(PATH)\n",
    "\n",
    "X = torch.from_numpy(test_data[0][:,:,feature_column]).to(torch.long)\n",
    "weight = torch.from_numpy(test_data[1][:,:,feature_column]).to(torch.float)\n",
    "utility_MNL,u0 = model_MNL([X,weight])\n",
    "utility_MNL = utility_MNL.detach().numpy()\n",
    "u0 = float(u0[0])\n",
    "pro_MNL = np.zeros(shape = utility_MNL.shape)\n",
    "for i in range(pro_MNL.shape[0]):\n",
    "    pro_MNL[i] = np.exp(utility_MNL[i])/(np.sum(np.exp(utility_MNL[i]))+np.exp(u0))\n",
    "\n",
    "ratio = 0\n",
    "high_low_ratio = []\n",
    "for i in range(pro_MNL.shape[0]):\n",
    "    ratio = ratio + (np.max(pro_MNL[i])- np.min(pro_MNL[i]))/np.mean(pro_MNL[i])\n",
    "    #index_array = np.argsort(-test_price[i])\n",
    "    #high_low_ratio.append(pro_MNL[i,index_array[1]]/pro_MNL[i,index_array[0]])\n",
    "\n",
    "rmse = []\n",
    "count_number1 = 0\n",
    "count_number3 = 0\n",
    "for i in range(pro_MNL.shape[0]):\n",
    "    rmse.append(np.sum((pro_MNL[i] - pro[i,0:30])**2) + (np.sum(pro_MNL[i]) - np.sum(pro[i,0:30]))**2)\n",
    "    pro_index = np.argsort(-pro_MNL[i])\n",
    "    if np.sum(test_label[i,:]) > 0:\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:1]):\n",
    "            count_number1 += 1\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:3]):\n",
    "            count_number3 += 1\n",
    "print(\" MNL Top1-acc: {:.4}\".format(count_number1/np.sum(test_label)))\n",
    "print(\" MNL Top3-acc: {:.4}\".format(count_number3/np.sum(test_label)))\n",
    "print(\" Averaged raito of MNL: {}\".format(ratio/10000))\n",
    "print(\"RMSE of MNL: {:.4}\".format(np.sqrt(sum(rmse)/(10000*31))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Assortment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "utility_MNL,u0 = model_MNL([X,weight])\n",
    "utility_MNL = utility_MNL.detach().numpy()\n",
    "u0 = float(u0[0])\n",
    "\n",
    "for cadinality in [30]:\n",
    "    print(\"{}:\".format(cadinality))\n",
    "    warnings.filterwarnings('ignore')\n",
    "    assortment_MNL = []\n",
    "    for i in tqdm(range(1000)):\n",
    "        assortment_MNL.append(at.MNL(np.exp(utility_MNL[i,0:100]-u0),price[i,0:100],capacity = cadinality))\n",
    "    products = []\n",
    "    price_MNL = []\n",
    "    for idx,item in enumerate(assortment_MNL):\n",
    "        temp_price = []\n",
    "        for j in range(utility_MNL.shape[1]):\n",
    "            if j in item:\n",
    "                products.append(idx*utility_MNL.shape[1]+j)\n",
    "                temp_price.append(price[idx,j])\n",
    "        price_MNL.append(temp_price)\n",
    "    valid_pro = true_model.predict(next_valid_data.loc[products]).detach().numpy()\n",
    "    print(np.sum(valid_pro[3][0:10]))\n",
    "    total_profit = 0\n",
    "    for i in range(len(price_MNL)):\n",
    "        total_profit += np.dot(valid_pro[i,0:len(price_MNL[i])],np.array(price_MNL[i]))\n",
    "    print(total_profit/1000)\n",
    "\n",
    "    assortment_array = np.zeros((1000,100))\n",
    "    for i,item in enumerate(assortment_MNL):\n",
    "        for j in item:\n",
    "            assortment_array[i,j] = 1\n",
    "    np.save(\"Assortment//MNL_assortment_\"+str(order_num )+'_'+str(cadinality)+\".npy\",assortment_array)\n",
    "    a = np.sum(assortment_array,axis = 1)\n",
    "    print(np.min(a),np.mean(a),np.max(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 DeepFM-based Choice Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training the DeepFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = data.shape[1]\n",
    "indices = np.random.permutation(total)\n",
    "k_fold = 5\n",
    "training_data = data[:,indices[0:int(total*(k_fold-1)/k_fold)],:,:]\n",
    "training_label = label[indices[0:int(total*(k_fold-1)/k_fold)],:]\n",
    "training_valid_data = data[:,indices[int(total*(k_fold-1)/k_fold):],:,:]\n",
    "training_valid_label = label[indices[int(total*(k_fold-1)/k_fold):],:]\n",
    "weight = int((training_label.shape[0]*training_label.shape[1]-np.sum(training_label))/np.sum(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_models//DeepFM_parameters_'+str(order_num )+'.pt'\n",
    "model_DeepFM = tp.train_DeepFM(training_data,training_label,training_valid_data,training_valid_label,weight1 = weight,path = PATH,LR = 0.05,feature_column=feature_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DeepFM Top1-acc: 0.2095\n",
      " DeepFM Top3-acc: 0.4412\n",
      " Averaged raito of DeepFM: 2.0982225510954855\n",
      "RMSE of DeepFM: 0.03312\n"
     ]
    }
   ],
   "source": [
    "PATH = 'trained_models//DeepFM_parameters_'+str(order_num )+'.pt'\n",
    "model_DeepFM = torch.load(PATH)\n",
    "purchase_pro = np.sum(label)/label.shape[0]\n",
    "\n",
    "X = torch.from_numpy(test_data[0][:,:,feature_column]).to(torch.long)\n",
    "weight = torch.from_numpy(test_data[1][:,:,feature_column]).to(torch.float)\n",
    "utility_DeepFM = model_DeepFM([X,weight])\n",
    "pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "\n",
    "ratio = 0\n",
    "high_low_ratio = []\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    ratio = ratio + (np.max(pro_DeepFM[i])- np.min(pro_DeepFM[i]))/np.mean(pro_DeepFM[i])\n",
    "    # index_array = np.argsort(-valid_price[i])\n",
    "    # high_low_ratio.append(pro_DeepFM[i,index_array[1]]/pro_DeepFM[i,index_array[0]])\n",
    "\n",
    "rmse = []\n",
    "count_number1 = 0\n",
    "count_number3 = 0\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    temp_pro = purchase_pro*pro_DeepFM[i]/np.sum(pro_DeepFM[i])\n",
    "    rmse.append(np.sum((temp_pro - pro[i,0:30])**2) + (np.sum(temp_pro) - np.sum(pro[i,0:30]))**2)\n",
    "    pro_index = np.argsort(-pro_DeepFM[i])\n",
    "    if np.sum(test_label[i,:]) > 0:\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:1]):\n",
    "            count_number1 += 1\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:3]):\n",
    "            count_number3 += 1\n",
    "print(\" DeepFM Top1-acc: {:.4}\".format(count_number1/np.sum(test_label)))\n",
    "print(\" DeepFM Top3-acc: {:.4}\".format(count_number3/np.sum(test_label)))\n",
    "print(\" Averaged raito of DeepFM: {}\".format(ratio/10000))\n",
    "print(\"RMSE of DeepFM: {:.4}\".format(np.sqrt(sum(rmse)/(10000*31))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Assortment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.82860732451886\n"
     ]
    }
   ],
   "source": [
    "X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "utility_DeepFM  = model_DeepFM([X,weight])\n",
    "pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "for cadinality in [30]:\n",
    "    warnings.filterwarnings('ignore')\n",
    "    assortment_DeepFM = []\n",
    "    for i in range(pro_DeepFM.shape[0]):\n",
    "        #length = len(assortment_ml[i])\n",
    "        revenue = pro_DeepFM[i,0:100]*price[i,0:100]\n",
    "        sort_index = np.argsort(-revenue)\n",
    "        assortment_DeepFM.append(sort_index[0:cadinality])\n",
    "\n",
    "    products = []\n",
    "    price_MNL = []\n",
    "    for idx,item in enumerate(assortment_DeepFM):\n",
    "        temp_price = []\n",
    "        for j in range(utility_MNL.shape[1]):\n",
    "            if j in item:\n",
    "                products.append(idx*utility_MNL.shape[1]+j)\n",
    "                temp_price.append(price[idx,j])\n",
    "        price_MNL.append(temp_price)\n",
    "    valid_pro = true_model.predict(next_valid_data.loc[products]).detach().numpy()\n",
    "    total_profit = 0\n",
    "    for i in range(len(price_MNL)):\n",
    "        total_profit += np.dot(valid_pro[i,0:len(price_MNL[i])],np.array(price_MNL[i]))\n",
    "    print(total_profit/1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 DeepFM-a based choice model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training the DeepFM-a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = data_with_assort_info.shape[1]\n",
    "indices = np.random.permutation(total) \n",
    "k_fold = 5\n",
    "training_data = data_with_assort_info[:,indices[0:int(total*(k_fold-1)/k_fold)],:,:]\n",
    "training_label = label[indices[0:int(total*(k_fold-1)/k_fold)],:]\n",
    "training_valid_data = data_with_assort_info[:,indices[int(total*(k_fold-1)/k_fold):],:,:]\n",
    "training_valid_label = label[indices[int(total*(k_fold-1)/k_fold):],:]\n",
    "weight = int((training_label.shape[0]*training_label.shape[1]-np.sum(training_label))/np.sum(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_models//DeepFM_parameters_with_assortment'+'_'+str(order_num )+'.pt'\n",
    "model_DeepFM = tp.train_DeepFM(training_data,training_label,training_valid_data,training_valid_label,model_name = 'Assortment',weight1 = weight,LR = 0.05,path = PATH,feature_column = [i for i in range(22)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DeepFM-assort Top1-acc: 0.2076\n",
      " DeepFM-assort Top3-acc: 0.4381\n",
      " Averaged raito of DeepFM-assort: 2.065047556900978\n",
      "RMSE of DeepFM-assort: 0.03339\n"
     ]
    }
   ],
   "source": [
    "PATH = 'trained_models//DeepFM_parameters_with_assortment'+'_'+str(order_num )+'.pt'\n",
    "model_DeepFM = torch.load(PATH)\n",
    "purchase_pro = np.sum(label)/label.shape[0]\n",
    "\n",
    "X = torch.from_numpy(test_data_with_assort_info[0][:,:,feature_column_swapping]).to(torch.long)\n",
    "weight = torch.from_numpy(test_data_with_assort_info[1][:,:,feature_column_swapping]).to(torch.float)\n",
    "utility_DeepFM  = model_DeepFM([X,weight])\n",
    "pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "\n",
    "ratio = 0\n",
    "high_low_ratio = []\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    ratio = ratio + (np.max(pro_DeepFM[i])- np.min(pro_DeepFM[i]))/np.mean(pro_DeepFM[i])\n",
    "    # index_array = np.argsort(-valid_price[i])\n",
    "    # high_low_ratio.append(pro_DeepFM[i,index_array[1]]/pro_DeepFM[i,index_array[0]])\n",
    "\n",
    "rmse = []\n",
    "count_number1 = 0\n",
    "count_number3 = 0\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    temp_pro = purchase_pro*pro_DeepFM[i]/np.sum(pro_DeepFM[i])\n",
    "    rmse.append(np.sum((temp_pro - pro[i,0:30])**2) + (np.sum(temp_pro) - np.sum(pro[i,0:30]))**2)\n",
    "    pro_index = np.argsort(-pro_DeepFM[i])\n",
    "    if np.sum(test_label[i,:]) > 0:\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:1]):\n",
    "            count_number1 += 1\n",
    "        if np.argmax(test_label[i,:]) in list(pro_index[0:3]):\n",
    "            count_number3 += 1\n",
    "print(\" DeepFM-assort Top1-acc: {:.4}\".format(count_number1/np.sum(test_label)))\n",
    "print(\" DeepFM-assort Top3-acc: {:.4}\".format(count_number3/np.sum(test_label)))\n",
    "print(\" Averaged raito of DeepFM-assort: {}\".format(ratio/10000))\n",
    "print(\"RMSE of DeepFM-assort: {:.4}\".format(np.sqrt(sum(rmse)/(10000*31))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Assortment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cadinality in [30]:\n",
    "    model_DeepFM1 = torch.load('trained_models//DeepFM_parameters_'+str(order_num )+'.pt')\n",
    "    X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "    weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "    utility_DeepFM  = model_DeepFM1([X,weight])\n",
    "    pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "    assortment_DeepFM = []\n",
    "    for i in range(pro_DeepFM.shape[0]):\n",
    "        #length = len(assortment_ml[i])\n",
    "        revenue = pro_DeepFM[i,0:100]*price[i,0:100]\n",
    "        sort_index = np.argsort(-revenue)\n",
    "        assortment_DeepFM.append(sort_index[0:cadinality])\n",
    "    warnings.filterwarnings('ignore')\n",
    "    assortment_ml = []\n",
    "    for i in tqdm(range(1000)):\n",
    "        assortment_ml.append(at.ml_assortment_swap(model_DeepFM,valid_data[:,i,0:100,:],price[i,0:100],assortment_DeepFM[i],capacity = cadinality,feature_column = [i for i in range(22)]))\n",
    "    products = []\n",
    "    price_MNL = []\n",
    "    for idx,item in enumerate(assortment_ml):\n",
    "        temp_price = []\n",
    "        for j in range(valid_data.shape[2]):\n",
    "            if j in item:\n",
    "                products.append(idx*valid_data.shape[2]+j)\n",
    "                temp_price.append(price[idx,j])\n",
    "        price_MNL.append(temp_price)\n",
    "    valid_pro = true_model.predict(next_valid_data.loc[products]).detach().numpy()\n",
    "    total_profit = 0\n",
    "    for i in range(len(price_MNL)):\n",
    "        total_profit += np.dot(valid_pro[i,0:len(price_MNL[i])],np.array(price_MNL[i]))\n",
    "    assortment_array = np.zeros((1000,100))\n",
    "    for i,item in enumerate(assortment_ml):\n",
    "        for j in item:\n",
    "            assortment_array[i,j] = 1   \n",
    "    np.save(\"Assortment//DeepFM_assortment_swapping_\"+str(order_num )+'_'+str(cadinality)+\".npy\",assortment_array)\n",
    "    print(total_profit/1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_dataset_for_transformer//{}.csv'.format(20000))\n",
    "weight_index = np.sum(train_data['booking_bool'])/(len(list(train_data['srch_id'].unique()))-np.sum(train_data['booking_bool']))\n",
    "if weight_index > 1:\n",
    "    pt_weight = [1,int(weight_index)]\n",
    "else:\n",
    "    pt_weight = [int(1/weight_index),1]\n",
    "#pt_weight = [8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modifiled_Transformer.train_model(train_data,pt_weight = pt_weight,model_name = \"20000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Obtaining the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_dataset_for_transformer//10000.csv')\n",
    "label = np.load('test_dataset//label__10000.npy')\n",
    "pro = np.load('test_dataset//pro__10000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1-Acc:  0.2035\n",
      "Top 3-Acc:  0.4351\n",
      "RMSE: 0.022282694032881138\n",
      " Averaged raito of Transformer: 6.182143734765053\n"
     ]
    }
   ],
   "source": [
    "pro_pred = Modifiled_Transformer.predict(test_data[test_data.columns[0:13]],max_num = 30, pt_weight = pt_weight,model_name = '20000')\n",
    "pro_pred = pro_pred.detach().numpy()\n",
    "total = 0\n",
    "count1 = 0\n",
    "count3 = 0\n",
    "RMSE_t = []\n",
    "ratio = 0\n",
    "for i in range(pro_pred.shape[0]):\n",
    "    ratio = ratio + (np.max(pro_pred[i,0:30])- np.min(pro_pred[i,0:30]))/np.mean(pro_pred[i,0:30])\n",
    "for i in range(pro_pred.shape[0]):\n",
    "    RMSE_t.append(np.sum((pro_pred[i,0:30]-pro[i,0:30])**2)+(np.sum(pro_pred[i,0:30]) - np.sum(pro[i,0:30]))**2)\n",
    "    if np.sum(label[i,:]) == 1:\n",
    "        total = total + 1\n",
    "        if np.argmax(label[i,:]) in np.argsort(-pro_pred[i,:])[0:1]:\n",
    "            count1 = count1 + 1\n",
    "        if np.argmax(label[i,:]) in np.argsort(-pro_pred[i,:])[0:3]:\n",
    "            count3 = count3 + 1\n",
    "print(\"Top 1-Acc:  {:0.4}\".format(count1/total))\n",
    "print(\"Top 3-Acc:  {:0.4}\".format(count3/total))\n",
    "print(\"RMSE: {}\".format(np.sqrt(sum(RMSE_t)/(len(RMSE_t)*31))))\n",
    "print(\" Averaged raito of Transformer: {}\".format(ratio/10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Get the assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cardinality in [30]:\n",
    "    print(cardinality)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    PATH = 'trained_models//DeepFM_parameters_'+str(20000 )+'.pt'\n",
    "    model_DeepFM = torch.load(PATH)\n",
    "    valid_data = np.load('new_products//valid_data_'+'.npy')\n",
    "    next_valid_data = pd.read_csv('new_products//next_valid_data'+'.csv') \n",
    "    price = np.array(next_valid_data['price_usd']).reshape(-1,100)\n",
    "    X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "    weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "    utility_DeepFM  = model_DeepFM([X,weight])\n",
    "    pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "    assortment_DeepFM = []\n",
    "    for i in range(pro_DeepFM.shape[0]):\n",
    "        #length = len(assortment_ml[i])\n",
    "        revenue = pro_DeepFM[i,0:100]*price[i,0:100]\n",
    "        sort_index = np.argsort(-revenue)\n",
    "        assortment_DeepFM.append(sort_index[0:cardinality])\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    assortment_transformer = []\n",
    "\n",
    "    for i in tqdm(range(1000)):\n",
    "        temp_df = next_valid_data[next_valid_data.srch_id == i]\n",
    "        temp_df.reset_index(drop = True,inplace = True)\n",
    "        temp_df = temp_df.loc[0:99,:]\n",
    "        temp_price = np.array(temp_df.loc[0:99,'price_usd'])\n",
    "        assortment_transformer.append(at.transformer_assortment_swap(\"20000\",temp_df,list(assortment_DeepFM[i]),pt_weight,temp_price))\n",
    "    products = []\n",
    "    price_MNL = []\n",
    "    for idx,item in enumerate(assortment_transformer):\n",
    "        temp_price = []\n",
    "        for j in range(valid_data.shape[2]):\n",
    "            if j in item:\n",
    "                products.append(idx*valid_data.shape[2]+j)\n",
    "                temp_price.append(price[idx,j])\n",
    "        price_MNL.append(temp_price)\n",
    "    valid_pro = true_model.predict(next_valid_data.loc[products]).detach().numpy()\n",
    "    total_profit = 0\n",
    "    for i in range(len(price_MNL)):\n",
    "        total_profit += np.dot(valid_pro[i,0:len(price_MNL[i])],np.array(price_MNL[i]))\n",
    "    print(total_profit/1000)\n",
    "    assortment_array = np.zeros((1000,100))\n",
    "    for i,item in enumerate(assortment_transformer):\n",
    "        for j in item:\n",
    "            assortment_array[i,j] = 1   \n",
    "    np.save(\"Assortment//Transformer_\"+str(20000)+'_'+str(cardinality)+\".npy\",assortment_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "596fdadd29b372637a8514aed73330d6c9d18319b553bb608f063ba205c13ba6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
