{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from Transformer import transformer\n",
    "import bulid_new_data as bnd\n",
    "from copy import deepcopy\n",
    "import traing_function as tp\n",
    "import assortment_process as at\n",
    "import warnings\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from alpermodel_1 import conicmc\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the new traing data or testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_size = 30 \n",
    "order_num = 20000\n",
    "file_name = \"train\"\n",
    "#order_num = 10000\n",
    "#file_name = \"test\"\n",
    "\n",
    "\n",
    "#c_rate is \\gamma\n",
    "for c_rate in [5,10,20,50,100,200]:\n",
    "    next_train_data = bnd.generate_data(order_num,int(choice_size+c_rate))\n",
    "    next_train_data.to_csv(file_name+\"_dataset\\\\\"+str(c_rate)+'_'+str(order_num)+'.csv',index=False)\n",
    "    \n",
    "    #transformer get lables for data\n",
    "    pro = transformer.true_model(next_train_data,order_num) \n",
    "    pro = pro.reshape(order_num,int(choice_size+c_rate))\n",
    "    label = np.zeros(shape = pro.shape)\n",
    "    for i in range(pro.shape[0]):\n",
    "        index = np.argmax(np.random.multinomial(1,pro[i]/np.sum(pro[i])))\n",
    "        label[i,index] = 1\n",
    "    label = label[:,0:choice_size]\n",
    "    pro = pro[:,0:choice_size]\n",
    "\n",
    "    del_feature = ['orderid']\n",
    "    features = [i for i in next_train_data.columns if i not in del_feature]\n",
    "    data_numpy = np.array(next_train_data[features]).reshape(order_num,int(choice_size+c_rate),-1)\n",
    "    np.save(file_name+\"_dataset_numpy\\\\data_\"+str(c_rate)+'_'+str(order_num)+'.npy',data_numpy[:,0:choice_size,:])\n",
    "    np.save(file_name+\"_dataset_numpy\\\\label_\"+str(c_rate)+'_'+str(order_num)+'.npy',label)\n",
    "\n",
    "    #Transform the numpy data\n",
    "    del_feature = ['orderid']\n",
    "    features = [i for i in next_train_data.columns if i not in del_feature]\n",
    "    data_np = np.array(next_train_data[features])\n",
    "    data_np_cate = np.zeros(shape = data_np.shape)\n",
    "    for idx,item in enumerate([11, 7, 97, 63, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]):\n",
    "        if item !=1 :\n",
    "            data_np_cate[:,idx] = data_np[:,idx]\n",
    "            data_np[:,idx] = 1\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(data_np)\n",
    "    data_np = scaler.transform(data_np)\n",
    "    for idx,item in enumerate([11, 7, 97, 63, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]):\n",
    "        if item != 1:\n",
    "            data_np[:,idx] = 1\n",
    "    data_np = data_np.reshape(-1,int(choice_size+c_rate),len(features))\n",
    "    data_np_cate = data_np_cate.reshape(-1,int(choice_size+c_rate),len(features))\n",
    "    data = np.array([data_np_cate[:,0:choice_size,:],data_np[:,0:choice_size,:]])\n",
    "\n",
    "    #Incorporate the assortment information for DeemFM-a\n",
    "    data_temp = np.zeros((order_num, choice_size, 9))\n",
    "    data_cate_temp = np.zeros((order_num, choice_size, 2))\n",
    "    for i in range(order_num):\n",
    "        min1 = np.min(data[1,i,:,5])\n",
    "        max1 = np.max(data[1,i,:,5])\n",
    "        mean1 = np.mean(data[1,i,:,5])\n",
    "        min2 = np.min(data[1,i,:,6])\n",
    "        max2 = np.max(data[1,i,:,6])\n",
    "        mean2 = np.mean(data[1,i,:,6])\n",
    "        min3 = np.min(data[1,i,:,7])\n",
    "        max3 = np.max(data[1,i,:,7])\n",
    "        mean3 = np.mean(data[1,i,:,7])\n",
    "        data_temp[i,:,0] = min1\n",
    "        data_temp[i,:,1] = max1\n",
    "        data_temp[i,:,2] = mean1\n",
    "        data_temp[i,:,3] = min2\n",
    "        data_temp[i,:,4] = max2\n",
    "        data_temp[i,:,5] = mean2\n",
    "        data_temp[i,:,6] = min3\n",
    "        data_temp[i,:,7] = max3\n",
    "        data_temp[i,:,8] = mean3 \n",
    "        for j in range(choice_size):\n",
    "            if data[1,i,j,6] == np.min(data[1,i,:,6]):\n",
    "                data_cate_temp[i,j,0] = 1\n",
    "            if data[1,i,j,6] == np.max(data[1,i,:,6]):\n",
    "                data_cate_temp[i,j,1] = 1\n",
    "    data_with_assort_info = np.array([np.concatenate([data[0],np.zeros((order_num, choice_size, 9)),data_cate_temp],axis = 2),np.concatenate([data[1],data_temp,np.ones((order_num,choice_size,2))],axis = 2)])\n",
    "\n",
    "    np.save(file_name+'_dataset_numpy_normalised\\\\data_'+str(c_rate)+'_'+str(order_num)+'.npy',data)\n",
    "    np.save(file_name+'_dataset_numpy_normalised\\\\label_'+str(c_rate)+'_'+str(order_num)+'.npy',label)\n",
    "    np.save(file_name+'_dataset_numpy_normalised\\\\data_with_assort_info_'+str(c_rate)+'_'+str(order_num )+'.npy',data_with_assort_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the decision-test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_rate in [200]:\n",
    "    print(c_rate)\n",
    "    next_valid_data = bnd.generate_data(1000,100+c_rate)\n",
    "    del_feature = ['orderid','alternative','orderlabel']\n",
    "    features = [i for i in next_valid_data.columns if i not in del_feature]\n",
    "    data_np = np.array(next_valid_data[features])\n",
    "    scaler = MinMaxScaler().fit(data_np)\n",
    "    data_np_cate = np.zeros(shape = data_np.shape)\n",
    "    for idx,item in enumerate([11, 7, 97, 63, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]):\n",
    "        if item !=1 :\n",
    "            data_np_cate[:,idx] = data_np[:,idx]\n",
    "            data_np[:,idx] = 1\n",
    "    data_np = scaler.transform(data_np)\n",
    "    for idx,item in enumerate([11, 7, 97, 63, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]):\n",
    "        if item != 1:\n",
    "            data_np[:,idx] = 1\n",
    "\n",
    "    data_np = data_np.reshape(-1,100+c_rate,len(features))\n",
    "    data_np_cate = data_np_cate.reshape(-1,100+c_rate,len(features))\n",
    "    valid_data = np.array([data_np_cate,data_np])\n",
    "    next_valid_data.to_csv('new_products\\\\next_valid_data_'+str(c_rate)+'.csv',index=False)\n",
    "    np.save('new_products\\\\valid_data_'+str(c_rate)+'.npy',valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 MNL-Based Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Training the MNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"trained_models_missfeatures\\\\MNL_parameters_special\"+str(c_rate)+'_'+str(order_num)+\".pt\"\n",
    "model_MNL = tp.train_data(data,label,NUM_EPOCHS = 100,BATCH_SIZE = 32,LR = 0.01,path = PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model\n",
    "PATH = \"trained_models_missfeatures\\\\MNL_parameters_special\"+str(c_rate)+'_'+str(order_num)+\".pt\"\n",
    "model_MNL = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Obtaining the utility of decision-test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "utility_MNL,u0 = model_MNL([X,weight])\n",
    "utility_MNL = utility_MNL.detach().numpy()\n",
    "u0 = float(u0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Make assortment decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "cadinality = 30\n",
    "assortment_MNL = []\n",
    "for i in tqdm(range(utility_MNL.shape[0])):\n",
    "    assortment_MNL.append(at.MNL(np.exp(utility_MNL[i,0:100]-u0),price[i,0:100],capacity = cadinality))\n",
    "products = []\n",
    "price_MNL = []\n",
    "for idx,item in enumerate(assortment_MNL):\n",
    "    for j in range(utility_MNL.shape[1]):\n",
    "        if j in item:\n",
    "            products.append(idx*utility_MNL.shape[1]+j)\n",
    "            price_MNL.append(price[idx,j])\n",
    "        elif j >= 100:\n",
    "            products.append(idx*utility_MNL.shape[1]+j)\n",
    "            price_MNL.append(0)\n",
    "valid_pro = true_model.true_model(next_valid_data.loc[products],1000)\n",
    "profit = np.dot(valid_pro,np.array(price_MNL))/1000\n",
    "print(cadinality,profit)\n",
    "assortment_array = np.zeros((1000,100))\n",
    "for i,item in enumerate(assortment_MNL):\n",
    "    for j in item:\n",
    "        assortment_array[i,j] = 1\n",
    "np.save(\"Assortment_missfearures\\\\MNL_assortment_special\"+str(c_rate)+\"_\"+str(order_num )+'_'+str(cadinality)+\".npy\",assortment_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 DeepFM-based Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training the DeepFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = data.shape[1]\n",
    "indices = np.random.permutation(total)\n",
    "k_fold = 5\n",
    "training_data = data[:,indices[0:int(total*(k_fold-1)/k_fold)],:,:]\n",
    "training_label = label[indices[0:int(total*(k_fold-1)/k_fold)],:]\n",
    "training_valid_data = data[:,indices[int(total*(k_fold-1)/k_fold):],:,:]\n",
    "training_valid_label = label[indices[int(total*(k_fold-1)/k_fold):],:]\n",
    "weight = int((training_label.shape[0]*training_label.shape[1]-np.sum(training_label))/np.sum(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "PATH = 'trained_models\\\\DeepFM_parameters_'+str(c_rate)+'_'+str(order_num )+'.pt'\n",
    "model_DeepFM = tp.train_DeepFM(training_data,training_label,training_valid_data,training_valid_label,weight1 = weight,path = PATH,LR = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Getting Probability for decision-test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "utility_DeepFM  = model_DeepFM([X,weight])\n",
    "pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Makeing assortment decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcadinality = 30\n",
    "warnings.filterwarnings('ignore')\n",
    "assortment_DeepFM = []\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    #length = len(assortment_ml[i])\n",
    "    revenue = pro_DeepFM[i,0:100]*price[i,0:100]\n",
    "    sort_index = np.argsort(-revenue)\n",
    "    assortment_DeepFM.append(sort_index[0:cadinality])\n",
    "\n",
    "products = []\n",
    "price_DeepFM = []\n",
    "for idx,item in enumerate(assortment_DeepFM):\n",
    "    for j in range(valid_data.shape[2]):\n",
    "        if j in item:\n",
    "            products.append(idx*valid_data.shape[2]+j)\n",
    "            price_DeepFM.append(price[idx,j])\n",
    "        elif j >= 100:\n",
    "            products.append(idx*valid_data.shape[2]+j)\n",
    "            price_DeepFM.append(0)\n",
    "valid_pro = true_model.true_model(next_valid_data.loc[products],1000)\n",
    "average_profit_ml = np.dot(valid_pro,np.array(price_DeepFM))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 DeepFM-a based choice model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training the DeepFM-a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = data_with_assort_info.shape[1]\n",
    "indices = np.random.permutation(total) \n",
    "k_fold = 5\n",
    "training_data = data_with_assort_info[:,indices[0:int(total*(k_fold-1)/k_fold)],:,:]\n",
    "training_label = label[indices[0:int(total*(k_fold-1)/k_fold)],:]\n",
    "training_valid_data = data_with_assort_info[:,indices[int(total*(k_fold-1)/k_fold):],:,:]\n",
    "training_valid_label = label[indices[int(total*(k_fold-1)/k_fold):],:]\n",
    "weight = int((training_label.shape[0]*training_label.shape[1]-np.sum(training_label))/np.sum(training_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_models_missfeatures\\\\DeepFM_parameters_with_assortment_special'+str(c_rate)+'_'+str(order_num )+'.pt'\n",
    "model_DeepFM = tp.train_DeepFM(training_data,training_label,training_valid_data,training_valid_label,model_name = 'Assortment',weight1 = weight,LR = 0.05,path = PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_models_missfeatures\\\\DeepFM_parameters_with_assortment_special'+str(c_rate)+'_'+str(order_num )+'.pt'\n",
    "model_DeepFM = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Making assortment decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadinality = NULL30\n",
    "model_DeepFM1 = torch.load('trained_models_missfeatures\\\\DeepFM_parameters_special'+str(c_rate)+'_'+str(order_num )+'.pt')\n",
    "X = torch.from_numpy(valid_data[0]).to(torch.long)\n",
    "weight = torch.from_numpy(valid_data[1]).to(torch.float)\n",
    "utility_DeepFM  = model_DeepFM1([X,weight])\n",
    "pro_DeepFM = torch.sigmoid(utility_DeepFM).detach().numpy()\n",
    "assortment_DeepFM = []\n",
    "for i in range(pro_DeepFM.shape[0]):\n",
    "    #length = len(assortment_ml[i])\n",
    "    revenue = pro_DeepFM[i,0:100]*price[i,0:100]\n",
    "    sort_index = np.argsort(-revenue)\n",
    "    assortment_DeepFM.append(sort_index[0:cadinality])\n",
    "warnings.filterwarnings('ignore')\n",
    "assortment_ml = []\n",
    "for i in tqdm(range(1000)):\n",
    "    assortment_ml.append(at.ml_assortment_swap(model_DeepFM,valid_data[:,i,0:100,:],price[i,0:100],assortment_DeepFM[i],capacity = cadinality,feature_column = feature_column_swapping))\n",
    "products = []\n",
    "price_ml = []\n",
    "for idx,item in enumerate(assortment_ml):\n",
    "    for j in range(valid_data.shape[2]):\n",
    "        if j in item:\n",
    "            products.append(idx*valid_data.shape[2]+j)\n",
    "            price_ml.append(price[idx,j])\n",
    "        elif j >= 100:\n",
    "            products.append(idx*valid_data.shape[2]+j)\n",
    "            price_ml.append(0)\n",
    "valid_pro = true_model.true_model(next_valid_data.loc[products],1000)\n",
    "average_profit_ml = np.dot(valid_pro,np.array(price_ml))/1000\n",
    "print(cadinality,average_profit_ml)\n",
    "assortment_array = np.zeros((1000,100))\n",
    "for i,item in enumerate(assortment_ml):\n",
    "    for j in item:\n",
    "        assortment_array[i,j] = 1   \n",
    "np.save(\"Assortment_missfearures\\\\DeepFM_assortment_swapping_special\"+str(c_rate)+\"_\"+str(order_num )+'_'+str(cadinality)+\".npy\",assortment_array)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dbc828abb6ce728a8b93da7b8ed7a63770a70f4d8c4b8f352b606b709a27647"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
